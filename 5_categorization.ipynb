{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fa87233",
   "metadata": {},
   "source": [
    "# Krystian Gronek & Katarzyna Piotrowska\n",
    "# Text Mining and Social Media Mining, final project - Analyzing men and women comments using NLP methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88dc8faa",
   "metadata": {},
   "source": [
    "# Loading packages and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "329449ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix, accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Naive Bayes Classifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "men = pd.read_csv('data/final_askmen.csv', sep = ';')\n",
    "women = pd.read_csv('data/final_askwomen.csv', sep = ';')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0794d08c",
   "metadata": {},
   "source": [
    "# Describing the categorization problem approach\n",
    "\n",
    "In this notebook we will try to predict from which subreddit a comment and post came. For that we will sue Multinomial Naive Bayes classifier and the input data will be the cleaned text of comments and posts submissions from /r/AskMen and /r/AskWomen subreddits. \n",
    "\n",
    "For categorization for both comments and posts we need convert each comment to its vectorized form representing the words from posts and comments and their numeric representation. We use 2 different representations of words:\n",
    "- as word counts, representing how many times a word appears in comments or posts in particular subreddit\n",
    "- as TF-IDF (Term Frequency - Inverse Document Frequency) score acting as weights corresponding to each word\n",
    "\n",
    "After that we divide the dataset into training and test parts and fit the model. Finally we make predictions for text categorization and assess the model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "904187a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 30809 entries, 0 to 14637\n",
      "Data columns (total 23 columns):\n",
      " #   Column                            Non-Null Count  Dtype  \n",
      "---  ------                            --------------  -----  \n",
      " 0   username                          30809 non-null  object \n",
      " 1   com_original                      30809 non-null  object \n",
      " 2   cleaned                           30809 non-null  object \n",
      " 3   cleaned_wo_sw                     30809 non-null  object \n",
      " 4   tokenized                         30809 non-null  object \n",
      " 5   stemmed                           30809 non-null  object \n",
      " 6   tokenized_wo_sw                   30809 non-null  object \n",
      " 7   submission_title                  30809 non-null  object \n",
      " 8   submission_title_cleaned          30809 non-null  object \n",
      " 9   submission_title_cleaned_wo_sw    30809 non-null  object \n",
      " 10  submission_title_tokenized        30809 non-null  object \n",
      " 11  submission_title_stemmed          30809 non-null  object \n",
      " 12  submission_title_tokenized_wo_sw  30809 non-null  object \n",
      " 13  comment_score                     30809 non-null  int64  \n",
      " 14  submission_ups                    30809 non-null  int64  \n",
      " 15  minmax                            30809 non-null  float64\n",
      " 16  minmax_grouped                    29921 non-null  float64\n",
      " 17  sentiment                         30809 non-null  object \n",
      " 18  comments_polarity                 30809 non-null  float64\n",
      " 19  comments_predicted_sentiment      30809 non-null  object \n",
      " 20  overestimated                     30809 non-null  int64  \n",
      " 21  underestimated                    30809 non-null  int64  \n",
      " 22  subreddit                         30809 non-null  object \n",
      "dtypes: float64(3), int64(4), object(16)\n",
      "memory usage: 5.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# add categorical variable that distincs whether a observation comes from /r/AskMen subreddit or /r/AskWomen subreddit \n",
    "men['subreddit'] = np.repeat(\"askmen\", len(men))\n",
    "women['subreddit'] = np.repeat(\"askwomen\", len(women))\n",
    "\n",
    "# merge two datasets into one\n",
    "df = pd.concat([men, women], axis = 0)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0ae7eb",
   "metadata": {},
   "source": [
    "# Categorization of comments according to subreddit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "254b8da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of Document-Term Matrix for comments text:\n",
      "Shape of Sparse Matrix:  (30809, 30197)\n",
      "Amount of non-zero occurences: 781735\n",
      "Sparsity: 0.08402686403341117 %\n",
      "\n",
      "\n",
      "Summary of predictions for vectorized text:\n",
      "Accuracy of Model - train data 84.41595326003166 %\n",
      "Accuracy of Model - test data 76.87439143135346 %\n",
      "\n",
      "\n",
      "Classification report for vectorized variable:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      askmen       0.84      0.83      0.84     16171\n",
      "    askwomen       0.81      0.83      0.82     14638\n",
      "\n",
      "    accuracy                           0.83     30809\n",
      "   macro avg       0.83      0.83      0.83     30809\n",
      "weighted avg       0.83      0.83      0.83     30809\n",
      "\n",
      "Confusion matrix for vectorized variable:\n",
      "[[13358  2813]\n",
      " [ 2453 12185]]\n",
      "\n",
      "\n",
      "Summary of predictions for TF-IDF transformed text:\n",
      "Accuracy of Model - train data 86.61906114334403 %\n",
      "Accuracy of Model - test data 77.6209023044466 %\n",
      "\n",
      "\n",
      "Classification report for TF-IDF transformed variable:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      askmen       0.85      0.86      0.86     16171\n",
      "    askwomen       0.85      0.83      0.84     14638\n",
      "\n",
      "    accuracy                           0.85     30809\n",
      "   macro avg       0.85      0.85      0.85     30809\n",
      "weighted avg       0.85      0.85      0.85     30809\n",
      "\n",
      "Confusion matrix for TF-IDF transformed variable:\n",
      "[[13942  2229]\n",
      " [ 2448 12190]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "comments_cleaned = df['cleaned']\n",
    "subreddits = df['subreddit']\n",
    "\n",
    "# Vectorization\n",
    "# count how many times does a word occur in each message, term frequency\n",
    "# weigh the counts, so that frequent tokens get lower weight, inverse document frequency\n",
    "# normalize the vectors to unit length, to abstract from the original text length, L2 norm \n",
    "cv = CountVectorizer().fit(comments_cleaned);\n",
    "X = cv.transform(comments_cleaned);\n",
    "\n",
    "# the bag-of-words counts for the entire SMS corpus\n",
    "print(\"Summary of Document-Term Matrix for comments text:\")\n",
    "print('Shape of Sparse Matrix: ',X.shape)\n",
    "print('Amount of non-zero occurences:',X.nnz)\n",
    "# Sparsity\n",
    "sparsity =(100.0 * X.nnz/(X.shape[0]*X.shape[1]))\n",
    "print('Sparsity: {}'.format(sparsity),\"%\")\n",
    "print('\\n')\n",
    "\n",
    "# Term weighting and normalization with TF-IDF\n",
    "tfidf_transformer=TfidfTransformer().fit(X)\n",
    "X_tfidf = tfidf_transformer.transform(X)\n",
    "\n",
    "# split the data into train and test parts\n",
    "comments_train, comments_test, subreddit_train, subreddit_test = train_test_split(X, subreddits, test_size=0.2, random_state = 9);\n",
    "\n",
    "# Naive Bayes Classifier\n",
    "model = MultinomialNB().fit(comments_train,subreddit_train);\n",
    "\n",
    "# what is the quality of our model?\n",
    "all_predictions_comments = model.predict(X)\n",
    "\n",
    "print(\"Summary of predictions for vectorized text:\")\n",
    "# Accuracy of our Model - train data\n",
    "print(\"Accuracy of Model - train data\", model.score(comments_train,subreddit_train)*100,\"%\")\n",
    "\n",
    "# Accuracy of our Model - test data\n",
    "print(\"Accuracy of Model - test data\", model.score(comments_test,subreddit_test)*100,\"%\")\n",
    "print(\"\\n\")\n",
    "print(\"Classification report for vectorized variable:\")\n",
    "print(classification_report(df['subreddit'],all_predictions_comments))\n",
    "print(\"Confusion matrix for vectorized variable:\")\n",
    "print(confusion_matrix(df['subreddit'],all_predictions_comments))\n",
    "print('\\n')\n",
    "\n",
    "# Accuracy after TF-IDF\n",
    "# split the data into train and test parts\n",
    "comments_train_TFIDF, comments_test_TFIDF, subreddit_train_TFIDF, subreddit_test_TFIDF = train_test_split(X_tfidf, subreddits, test_size=0.2, random_state = 9);\n",
    "\n",
    "# Naive Bayes Classifier + fit the model to train data\n",
    "model = MultinomialNB().fit(comments_train_TFIDF,subreddit_train_TFIDF);\n",
    "\n",
    "# what is the quality of our model?\n",
    "all_predictions_comments_TFIDF = model.predict(X_tfidf)\n",
    "\n",
    "print(\"Summary of predictions for TF-IDF transformed text:\")\n",
    "# Accuracy of our Model - train data\n",
    "print(\"Accuracy of Model - train data\", model.score(comments_train_TFIDF,subreddit_train_TFIDF)*100,\"%\")\n",
    "\n",
    "# Accuracy of our Model - test data\n",
    "print(\"Accuracy of Model - test data\", model.score(comments_test_TFIDF,subreddit_test_TFIDF)*100,\"%\")\n",
    "print('\\n')\n",
    "\n",
    "print(\"Classification report for TF-IDF transformed variable:\")\n",
    "print(classification_report(df['subreddit'],all_predictions_comments_TFIDF))\n",
    "print(\"Confusion matrix for TF-IDF transformed variable:\")\n",
    "print(confusion_matrix(df['subreddit'],all_predictions_comments_TFIDF))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb77bd0e",
   "metadata": {},
   "source": [
    "### Results - categorization of comments according to subreddit\n",
    "\n",
    "Looking at the sparsity of matrix we can wee that it is equal to 0.08%. \n",
    "\n",
    "Accuracy of predictions for vectorized, word counts transformed text were accurate in 84.4% of the comments in train data and 76.9% in test data. For TF-IDF transformed text data we can see that the accuracy of the model increased slightly. Now the predictions were accurate in 86.6% in train data and 77.6% in test data. We can also see the classification reports and confusion matrices for vectorized and TF-IDF transformed text.\n",
    "\n",
    "Overall we can say the categorization predictions were relatively high, suggesting that there is a distinction in how men and women write replies on Reddit and the selection of the words that they are using."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61351f69",
   "metadata": {},
   "source": [
    "# Predicting from which subreddit does a post come from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a02095e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of Document-Term Matrix for posts text:\n",
      "Shape of Sparse Matrix:  (30809, 1448)\n",
      "Amount of non-zero occurences: 369515\n",
      "Sparsity: 0.8282966572335091 %\n",
      "\n",
      "\n",
      "Summary of predictions for vectorized posts text:\n",
      "Accuracy of Model - train data 98.23913660891792 %\n",
      "Accuracy of Model - test data 98.10126582278481 %\n",
      "\n",
      "\n",
      "Classification report for vectorized variable:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      askmen       0.99      0.98      0.98     16171\n",
      "    askwomen       0.97      0.99      0.98     14638\n",
      "\n",
      "    accuracy                           0.98     30809\n",
      "   macro avg       0.98      0.98      0.98     30809\n",
      "weighted avg       0.98      0.98      0.98     30809\n",
      "\n",
      "Confusion matrix for vectorized variable:\n",
      "[[15799   372]\n",
      " [  179 14459]]\n",
      "\n",
      "\n",
      "Summary of predictions for TF-IDF transformed posts text:\n",
      "Accuracy of Model - train data 98.93293301415994 %\n",
      "Accuracy of Model - test data 98.83154819863681 %\n",
      "\n",
      "\n",
      "Classification report for TF-IDF transformed variable:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      askmen       0.99      0.98      0.99     16171\n",
      "    askwomen       0.98      0.99      0.99     14638\n",
      "\n",
      "    accuracy                           0.99     30809\n",
      "   macro avg       0.99      0.99      0.99     30809\n",
      "weighted avg       0.99      0.99      0.99     30809\n",
      "\n",
      "Confusion matrix for TF-IDF transformed variable:\n",
      "[[15917   254]\n",
      " [   81 14557]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "posts_cleaned = df['submission_title_cleaned']\n",
    "subreddits = df['subreddit']\n",
    "\n",
    "# Vectorization\n",
    "# count how many times does a word occur in each message, term frequency\n",
    "# weigh the counts, so that frequent tokens get lower weight, inverse document frequency\n",
    "# normalize the vectors to unit length, to abstract from the original text length, L2 norm \n",
    "cv = CountVectorizer().fit(posts_cleaned);\n",
    "X = cv.transform(posts_cleaned);\n",
    "\n",
    "# the bag-of-words counts for the entire SMS corpus\n",
    "print(\"Summary of Document-Term Matrix for posts text:\")\n",
    "print('Shape of Sparse Matrix: ',X.shape)\n",
    "print('Amount of non-zero occurences:',X.nnz)\n",
    "# Sparsity\n",
    "sparsity =(100.0 * X.nnz/(X.shape[0]*X.shape[1]))\n",
    "print('Sparsity: {}'.format(sparsity),\"%\")\n",
    "print('\\n')\n",
    "\n",
    "# Term weighting and normalization with TF-IDF\n",
    "tfidf_transformer=TfidfTransformer().fit(X)\n",
    "X_tfidf = tfidf_transformer.transform(X)\n",
    "\n",
    "# split the data into train and test parts\n",
    "posts_train, posts_test, subreddit_train, subreddit_test = train_test_split(X, subreddits, test_size=0.2, random_state = 9);\n",
    "\n",
    "# Naive Bayes Classifier + fit the model to train data\n",
    "model = MultinomialNB().fit(posts_train,subreddit_train);\n",
    "\n",
    "# what is the quality of our model?\n",
    "all_predictions_posts = model.predict(X)\n",
    "\n",
    "print(\"Summary of predictions for vectorized posts text:\")\n",
    "# Accuracy of our Model - train data\n",
    "print(\"Accuracy of Model - train data\", model.score(posts_train,subreddit_train)*100,\"%\")\n",
    "\n",
    "# Accuracy of our Model - test data\n",
    "print(\"Accuracy of Model - test data\", model.score(posts_test,subreddit_test)*100,\"%\")\n",
    "print('\\n')\n",
    "print(\"Classification report for vectorized variable:\")\n",
    "print(classification_report(df['subreddit'],all_predictions_posts))\n",
    "print(\"Confusion matrix for vectorized variable:\")\n",
    "print(confusion_matrix(df['subreddit'],all_predictions_posts))\n",
    "print('\\n')\n",
    "\n",
    "# Accuracy after TF-IDF\n",
    "# split the data into train and test parts\n",
    "posts_train_TFIDF, posts_test_TFIDF, subreddit_train_TFIDF, subreddit_test_TFIDF = train_test_split(X_tfidf, subreddits, test_size=0.2, random_state = 9);\n",
    "\n",
    "# Naive Bayes Classifier + fit the model to train data\n",
    "model = MultinomialNB().fit(posts_train_TFIDF,subreddit_train_TFIDF);\n",
    "\n",
    "# what is the quality of our model?\n",
    "all_predictions_posts_TFIDF = model.predict(X_tfidf)\n",
    "\n",
    "print(\"Summary of predictions for TF-IDF transformed posts text:\")\n",
    "# Accuracy of our Model - train data\n",
    "print(\"Accuracy of Model - train data\", model.score(posts_train_TFIDF,subreddit_train_TFIDF)*100,\"%\")\n",
    "\n",
    "# Accuracy of our Model - test data\n",
    "print(\"Accuracy of Model - test data\", model.score(posts_test_TFIDF,subreddit_test_TFIDF)*100,\"%\")\n",
    "print('\\n')\n",
    "print(\"Classification report for TF-IDF transformed variable:\")\n",
    "print(classification_report(df['subreddit'],all_predictions_posts_TFIDF))\n",
    "print(\"Confusion matrix for TF-IDF transformed variable:\")\n",
    "print(confusion_matrix(df['subreddit'],all_predictions_posts_TFIDF))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f2abf5",
   "metadata": {},
   "source": [
    "### Results - categorization of posts titles according to subreddit\n",
    "\n",
    "Looking at the sparsity of matrix for posts titles we can wee that it is equal to 0.8%. \n",
    "\n",
    "For posts titles accuracy of the model predicting posts titles subreddit origin were very accurate. For vectorized text it was equal to 98.2% and 98.1% for train and test data respectively. The predictions were again increased a bit with TF-IDF transformation. Now the accuracty inceased to 98.9% for train data and 98.8% for test data. \n",
    "\n",
    "The accuracy of prediction for posts titles origin subreddit seem pretty impressive. It is important to note that as for comments we can safely assume that reply comments were written by their respective sexes because we can assume that asking a question on selected sex subreddit should result from their sex user. This is not the case for posts titles as they are usually questions asked by any sex (both men and women). Nonetheless we can see that there is a very big distinct way or word composition that are used in these different subreddits which results in such big prediction accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba12e46",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "Overall we can say that there is a significant difference in how write both their comments and posts on examined subreddits. The categorization predictions were very high and based on the scores alone we could conclude that there are men and women do use different language when online."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
