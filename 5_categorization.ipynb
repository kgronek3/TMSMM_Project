{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fa87233",
   "metadata": {},
   "source": [
    "# Krystian Gronek & Katarzyna Piotrowska\n",
    "# Text Mining and Social Media Mining, final project - Analyzing men and women comments using NLP methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88dc8faa",
   "metadata": {},
   "source": [
    "# Loading packages and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "329449ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix, accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Naive Bayes Classifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "men = pd.read_csv('data/final_askmen.csv', sep = ';')\n",
    "women = pd.read_csv('data/final_askwomen.csv', sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "904187a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 30809 entries, 0 to 14637\n",
      "Data columns (total 23 columns):\n",
      " #   Column                            Non-Null Count  Dtype  \n",
      "---  ------                            --------------  -----  \n",
      " 0   username                          30809 non-null  object \n",
      " 1   com_original                      30809 non-null  object \n",
      " 2   cleaned                           30809 non-null  object \n",
      " 3   cleaned_wo_sw                     30809 non-null  object \n",
      " 4   tokenized                         30809 non-null  object \n",
      " 5   stemmed                           30809 non-null  object \n",
      " 6   tokenized_wo_sw                   30809 non-null  object \n",
      " 7   submission_title                  30809 non-null  object \n",
      " 8   submission_title_cleaned          30809 non-null  object \n",
      " 9   submission_title_cleaned_wo_sw    30809 non-null  object \n",
      " 10  submission_title_tokenized        30809 non-null  object \n",
      " 11  submission_title_stemmed          30809 non-null  object \n",
      " 12  submission_title_tokenized_wo_sw  30809 non-null  object \n",
      " 13  comment_score                     30809 non-null  int64  \n",
      " 14  submission_ups                    30809 non-null  int64  \n",
      " 15  minmax                            30809 non-null  float64\n",
      " 16  minmax_grouped                    29921 non-null  float64\n",
      " 17  sentiment                         30809 non-null  object \n",
      " 18  comments_polarity                 30809 non-null  float64\n",
      " 19  comments_predicted_sentiment      30809 non-null  object \n",
      " 20  overestimated                     30809 non-null  int64  \n",
      " 21  underestimated                    30809 non-null  int64  \n",
      " 22  subreddit                         30809 non-null  object \n",
      "dtypes: float64(3), int64(4), object(16)\n",
      "memory usage: 5.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# add categorical variable that distincs weather a observation comes from /r/AskMen subreddit or /r/AskWomen subreddit \n",
    "men['subreddit'] = np.repeat(\"askmen\", len(men))\n",
    "women['subreddit'] = np.repeat(\"askwomen\", len(women))\n",
    "\n",
    "# merge two datasets into one\n",
    "df = pd.concat([men, women], axis = 0)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0ae7eb",
   "metadata": {},
   "source": [
    "# Categorization of comments according to subreddit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "254b8da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Sparse Matrix:  (30809, 30197)\n",
      "Amount of non-zero occurences: 781735\n",
      "Sparsity: 0 %\n",
      "TfidfTransformer()\n",
      "(30809, 30197)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.776209023044466"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['askmen' 'askmen' 'askmen' ... 'askwomen' 'askwomen' 'askwomen']\n",
      "Accuracy of Model - train data 86.61906114334403 %\n",
      "Accuracy of Model - test data 77.6209023044466 %\n"
     ]
    }
   ],
   "source": [
    "comments_cleaned = df['cleaned']\n",
    "subreddits = df['subreddit']\n",
    "\n",
    "# Vectorization\n",
    "# count how many times does a word occur in each message, term frequency\n",
    "# weigh the counts, so that frequent tokens get lower weight, inverse document frequency\n",
    "# normalize the vectors to unit length, to abstract from the original text length, L2 norm \n",
    "cv = CountVectorizer().fit(comments_cleaned);\n",
    "X = cv.transform(comments_cleaned);\n",
    "\n",
    "# the bag-of-words counts for the entire SMS corpus\n",
    "print('Shape of Sparse Matrix: ',X.shape)\n",
    "print('Amount of non-zero occurences:',X.nnz)\n",
    "\n",
    "# Sparsity\n",
    "sparsity =(100.0 * X.nnz/(X.shape[0]*X.shape[1]))\n",
    "print('Sparsity: {}'.format(round(sparsity)),\"%\")\n",
    "# THE SPARSITY IS equal to 0 % which is good.\n",
    "\n",
    "# Term weighting and normalization with TF-IDF\n",
    "tfidf_transformer=TfidfTransformer().fit(X)\n",
    "X_tfidf = tfidf_transformer.transform(X)\n",
    "print(tfidf_transformer)\n",
    "print(X_tfidf.shape)\n",
    "\n",
    "# split the data into train and test parts\n",
    "comment_train, comment_test, subreddit_train, subreddit_test = train_test_split(X_tfidf, subreddits, test_size=0.2, random_state = 9);\n",
    "\n",
    "# Naive Bayes Classifier\n",
    "model = MultinomialNB();\n",
    "model.fit(comment_train,subreddit_train);\n",
    "model.score(comment_test,subreddit_test);\n",
    "\n",
    "# what is the quality of our model?\n",
    "all_predictions = model.predict(X_tfidf)\n",
    "print(all_predictions)\n",
    "\n",
    "# Accuracy of our Model - train data\n",
    "print(\"Accuracy of Model - train data\", model.score(comment_train,subreddit_train)*100,\"%\")\n",
    "\n",
    "# Accuracy of our Model - test data\n",
    "print(\"Accuracy of Model - test data\", model.score(comment_test,subreddit_test)*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed325300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>com_original</th>\n",
       "      <th>cleaned</th>\n",
       "      <th>cleaned_wo_sw</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>tokenized_wo_sw</th>\n",
       "      <th>submission_title</th>\n",
       "      <th>submission_title_cleaned</th>\n",
       "      <th>submission_title_cleaned_wo_sw</th>\n",
       "      <th>...</th>\n",
       "      <th>comment_score</th>\n",
       "      <th>submission_ups</th>\n",
       "      <th>minmax</th>\n",
       "      <th>minmax_grouped</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>comments_polarity</th>\n",
       "      <th>comments_predicted_sentiment</th>\n",
       "      <th>overestimated</th>\n",
       "      <th>underestimated</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8483</td>\n",
       "      <td>Thank fuck... So many great posts buried under...</td>\n",
       "      <td>thank fuck so many great posts buried under id...</td>\n",
       "      <td>thank fuck many great posts buried idiotic kar...</td>\n",
       "      <td>['thank', 'fuck', 'so', 'many', 'great', 'post...</td>\n",
       "      <td>thank fuck mani great post buri idiot karma wh...</td>\n",
       "      <td>['thank', 'fuck', 'many', 'great', 'posts', 'b...</td>\n",
       "      <td>BONK! Overly sexual questions are no longer al...</td>\n",
       "      <td>bonk overly sexual questions are no longer all...</td>\n",
       "      <td>bonk overly sexual questions longer allowed</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>13949</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>positive</td>\n",
       "      <td>-0.0571</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>askmen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Zeezprahh</td>\n",
       "      <td>Well fuck me and suck me sideways, it's a deal!</td>\n",
       "      <td>well fuck me and suck me sideways its a deal</td>\n",
       "      <td>well fuck suck sideways deal</td>\n",
       "      <td>['well', 'fuck', 'me', 'and', 'suck', 'me', 's...</td>\n",
       "      <td>well fuck suck sideway deal</td>\n",
       "      <td>['well', 'fuck', 'suck', 'sideways', 'deal']</td>\n",
       "      <td>BONK! Overly sexual questions are no longer al...</td>\n",
       "      <td>bonk overly sexual questions are no longer all...</td>\n",
       "      <td>bonk overly sexual questions longer allowed</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>13949</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>positive</td>\n",
       "      <td>-0.6486</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>askmen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>skinny_gator</td>\n",
       "      <td>I'm dying over here lmao\\n\\nThis is amazing. A...</td>\n",
       "      <td>im dying over here lmao this is amazing and ye...</td>\n",
       "      <td>im dying lmao amazing yes ask men straight bec...</td>\n",
       "      <td>['im', 'dying', 'over', 'here', 'lmao', 'this'...</td>\n",
       "      <td>im die lmao amaz ye ask men straight becom nsf...</td>\n",
       "      <td>['im', 'dying', 'lmao', 'amazing', 'yes', 'ask...</td>\n",
       "      <td>BONK! Overly sexual questions are no longer al...</td>\n",
       "      <td>bonk overly sexual questions are no longer all...</td>\n",
       "      <td>bonk overly sexual questions longer allowed</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>13949</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.9062</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>askmen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dyslexicbunny</td>\n",
       "      <td>Oh good. I got tired of reading all that crap....</td>\n",
       "      <td>oh good i got tired of reading all that crap l...</td>\n",
       "      <td>oh good got tired reading crap lets talk comfy...</td>\n",
       "      <td>['oh', 'good', 'i', 'got', 'tired', 'of', 'rea...</td>\n",
       "      <td>oh good got tire read crap let talk comfi hell...</td>\n",
       "      <td>['oh', 'good', 'got', 'tired', 'reading', 'cra...</td>\n",
       "      <td>BONK! Overly sexual questions are no longer al...</td>\n",
       "      <td>bonk overly sexual questions are no longer all...</td>\n",
       "      <td>bonk overly sexual questions longer allowed</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>13949</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>positive</td>\n",
       "      <td>-0.8020</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>askmen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BantyRed</td>\n",
       "      <td>I thought it was just me. I joined right befor...</td>\n",
       "      <td>i thought it was just me i joined right before...</td>\n",
       "      <td>thought joined right horny came figured horny ...</td>\n",
       "      <td>['i', 'thought', 'it', 'was', 'just', 'me', 'i...</td>\n",
       "      <td>thought join right horni came figur horni peopl</td>\n",
       "      <td>['thought', 'joined', 'right', 'horny', 'came'...</td>\n",
       "      <td>BONK! Overly sexual questions are no longer al...</td>\n",
       "      <td>bonk overly sexual questions are no longer all...</td>\n",
       "      <td>bonk overly sexual questions longer allowed</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>13949</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>-0.058824</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>askmen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14633</th>\n",
       "      <td>nocturnal_confidant</td>\n",
       "      <td>\\nI understand the question. But I am going tr...</td>\n",
       "      <td>i understand the question but i am going try t...</td>\n",
       "      <td>understand question going try longer compare r...</td>\n",
       "      <td>['i', 'understand', 'the', 'question', 'but', ...</td>\n",
       "      <td>understand question go tri longer compar right...</td>\n",
       "      <td>['understand', 'question', 'going', 'try', 'lo...</td>\n",
       "      <td>What age do you consider to be “in your prime”?</td>\n",
       "      <td>what age do you consider to be in your prime</td>\n",
       "      <td>age consider prime</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>373</td>\n",
       "      <td>-0.076923</td>\n",
       "      <td>-0.785714</td>\n",
       "      <td>negative</td>\n",
       "      <td>-0.3940</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>askwomen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14634</th>\n",
       "      <td>D-Spornak</td>\n",
       "      <td>I'm hoping it's coming up soon.</td>\n",
       "      <td>im hoping its coming up soon</td>\n",
       "      <td>im hoping coming soon</td>\n",
       "      <td>['im', 'hoping', 'its', 'coming', 'up', 'soon']</td>\n",
       "      <td>im hope come soon</td>\n",
       "      <td>['im', 'hoping', 'coming', 'soon']</td>\n",
       "      <td>What age do you consider to be “in your prime”?</td>\n",
       "      <td>what age do you consider to be in your prime</td>\n",
       "      <td>age consider prime</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>373</td>\n",
       "      <td>-0.076923</td>\n",
       "      <td>-0.785714</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.4215</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>askwomen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14635</th>\n",
       "      <td>Non-Priority-98</td>\n",
       "      <td>Hmmmm I would think that it is in stable times...</td>\n",
       "      <td>hmmmm i would think that it is in stable times...</td>\n",
       "      <td>hmmmm would think stable times short substanti...</td>\n",
       "      <td>['hmmmm', 'i', 'would', 'think', 'that', 'it',...</td>\n",
       "      <td>hmmmm would think stabl time short substanti e...</td>\n",
       "      <td>['hmmmm', 'would', 'think', 'stable', 'times',...</td>\n",
       "      <td>What age do you consider to be “in your prime”?</td>\n",
       "      <td>what age do you consider to be in your prime</td>\n",
       "      <td>age consider prime</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>373</td>\n",
       "      <td>-0.076923</td>\n",
       "      <td>-0.785714</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.9136</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>askwomen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14636</th>\n",
       "      <td>Irinakusx</td>\n",
       "      <td>20 it is advisable to take care of your health...</td>\n",
       "      <td>it is advisable to take care of your health at...</td>\n",
       "      <td>advisable take care health time always active ...</td>\n",
       "      <td>['it', 'is', 'advisable', 'to', 'take', 'care'...</td>\n",
       "      <td>advis take care health time alway activ desir</td>\n",
       "      <td>['advisable', 'take', 'care', 'health', 'time'...</td>\n",
       "      <td>What age do you consider to be “in your prime”?</td>\n",
       "      <td>what age do you consider to be in your prime</td>\n",
       "      <td>age consider prime</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>373</td>\n",
       "      <td>-0.076923</td>\n",
       "      <td>-0.785714</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.8020</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>askwomen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14637</th>\n",
       "      <td>cuddliest_friend</td>\n",
       "      <td>If i feel that this is the Part of my Life whe...</td>\n",
       "      <td>if i feel that this is the part of my life whe...</td>\n",
       "      <td>feel part life mental health physikal healthst...</td>\n",
       "      <td>['if', 'i', 'feel', 'that', 'this', 'is', 'the...</td>\n",
       "      <td>feel part life mental health physik healthstre...</td>\n",
       "      <td>['feel', 'part', 'life', 'mental', 'health', '...</td>\n",
       "      <td>What age do you consider to be “in your prime”?</td>\n",
       "      <td>what age do you consider to be in your prime</td>\n",
       "      <td>age consider prime</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>373</td>\n",
       "      <td>-0.076923</td>\n",
       "      <td>-0.785714</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.3826</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>askwomen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30809 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  username                                       com_original  \\\n",
       "0                     8483  Thank fuck... So many great posts buried under...   \n",
       "1                Zeezprahh    Well fuck me and suck me sideways, it's a deal!   \n",
       "2             skinny_gator  I'm dying over here lmao\\n\\nThis is amazing. A...   \n",
       "3            dyslexicbunny  Oh good. I got tired of reading all that crap....   \n",
       "4                 BantyRed  I thought it was just me. I joined right befor...   \n",
       "...                    ...                                                ...   \n",
       "14633  nocturnal_confidant  \\nI understand the question. But I am going tr...   \n",
       "14634            D-Spornak                    I'm hoping it's coming up soon.   \n",
       "14635      Non-Priority-98  Hmmmm I would think that it is in stable times...   \n",
       "14636            Irinakusx  20 it is advisable to take care of your health...   \n",
       "14637     cuddliest_friend  If i feel that this is the Part of my Life whe...   \n",
       "\n",
       "                                                 cleaned  \\\n",
       "0      thank fuck so many great posts buried under id...   \n",
       "1           well fuck me and suck me sideways its a deal   \n",
       "2      im dying over here lmao this is amazing and ye...   \n",
       "3      oh good i got tired of reading all that crap l...   \n",
       "4      i thought it was just me i joined right before...   \n",
       "...                                                  ...   \n",
       "14633  i understand the question but i am going try t...   \n",
       "14634                       im hoping its coming up soon   \n",
       "14635  hmmmm i would think that it is in stable times...   \n",
       "14636  it is advisable to take care of your health at...   \n",
       "14637  if i feel that this is the part of my life whe...   \n",
       "\n",
       "                                           cleaned_wo_sw  \\\n",
       "0      thank fuck many great posts buried idiotic kar...   \n",
       "1                           well fuck suck sideways deal   \n",
       "2      im dying lmao amazing yes ask men straight bec...   \n",
       "3      oh good got tired reading crap lets talk comfy...   \n",
       "4      thought joined right horny came figured horny ...   \n",
       "...                                                  ...   \n",
       "14633  understand question going try longer compare r...   \n",
       "14634                              im hoping coming soon   \n",
       "14635  hmmmm would think stable times short substanti...   \n",
       "14636  advisable take care health time always active ...   \n",
       "14637  feel part life mental health physikal healthst...   \n",
       "\n",
       "                                               tokenized  \\\n",
       "0      ['thank', 'fuck', 'so', 'many', 'great', 'post...   \n",
       "1      ['well', 'fuck', 'me', 'and', 'suck', 'me', 's...   \n",
       "2      ['im', 'dying', 'over', 'here', 'lmao', 'this'...   \n",
       "3      ['oh', 'good', 'i', 'got', 'tired', 'of', 'rea...   \n",
       "4      ['i', 'thought', 'it', 'was', 'just', 'me', 'i...   \n",
       "...                                                  ...   \n",
       "14633  ['i', 'understand', 'the', 'question', 'but', ...   \n",
       "14634    ['im', 'hoping', 'its', 'coming', 'up', 'soon']   \n",
       "14635  ['hmmmm', 'i', 'would', 'think', 'that', 'it',...   \n",
       "14636  ['it', 'is', 'advisable', 'to', 'take', 'care'...   \n",
       "14637  ['if', 'i', 'feel', 'that', 'this', 'is', 'the...   \n",
       "\n",
       "                                                 stemmed  \\\n",
       "0      thank fuck mani great post buri idiot karma wh...   \n",
       "1                            well fuck suck sideway deal   \n",
       "2      im die lmao amaz ye ask men straight becom nsf...   \n",
       "3      oh good got tire read crap let talk comfi hell...   \n",
       "4        thought join right horni came figur horni peopl   \n",
       "...                                                  ...   \n",
       "14633  understand question go tri longer compar right...   \n",
       "14634                                  im hope come soon   \n",
       "14635  hmmmm would think stabl time short substanti e...   \n",
       "14636      advis take care health time alway activ desir   \n",
       "14637  feel part life mental health physik healthstre...   \n",
       "\n",
       "                                         tokenized_wo_sw  \\\n",
       "0      ['thank', 'fuck', 'many', 'great', 'posts', 'b...   \n",
       "1           ['well', 'fuck', 'suck', 'sideways', 'deal']   \n",
       "2      ['im', 'dying', 'lmao', 'amazing', 'yes', 'ask...   \n",
       "3      ['oh', 'good', 'got', 'tired', 'reading', 'cra...   \n",
       "4      ['thought', 'joined', 'right', 'horny', 'came'...   \n",
       "...                                                  ...   \n",
       "14633  ['understand', 'question', 'going', 'try', 'lo...   \n",
       "14634                 ['im', 'hoping', 'coming', 'soon']   \n",
       "14635  ['hmmmm', 'would', 'think', 'stable', 'times',...   \n",
       "14636  ['advisable', 'take', 'care', 'health', 'time'...   \n",
       "14637  ['feel', 'part', 'life', 'mental', 'health', '...   \n",
       "\n",
       "                                        submission_title  \\\n",
       "0      BONK! Overly sexual questions are no longer al...   \n",
       "1      BONK! Overly sexual questions are no longer al...   \n",
       "2      BONK! Overly sexual questions are no longer al...   \n",
       "3      BONK! Overly sexual questions are no longer al...   \n",
       "4      BONK! Overly sexual questions are no longer al...   \n",
       "...                                                  ...   \n",
       "14633    What age do you consider to be “in your prime”?   \n",
       "14634    What age do you consider to be “in your prime”?   \n",
       "14635    What age do you consider to be “in your prime”?   \n",
       "14636    What age do you consider to be “in your prime”?   \n",
       "14637    What age do you consider to be “in your prime”?   \n",
       "\n",
       "                                submission_title_cleaned  \\\n",
       "0      bonk overly sexual questions are no longer all...   \n",
       "1      bonk overly sexual questions are no longer all...   \n",
       "2      bonk overly sexual questions are no longer all...   \n",
       "3      bonk overly sexual questions are no longer all...   \n",
       "4      bonk overly sexual questions are no longer all...   \n",
       "...                                                  ...   \n",
       "14633      what age do you consider to be in your prime    \n",
       "14634      what age do you consider to be in your prime    \n",
       "14635      what age do you consider to be in your prime    \n",
       "14636      what age do you consider to be in your prime    \n",
       "14637      what age do you consider to be in your prime    \n",
       "\n",
       "                    submission_title_cleaned_wo_sw  ... comment_score  \\\n",
       "0      bonk overly sexual questions longer allowed  ...            11   \n",
       "1      bonk overly sexual questions longer allowed  ...             8   \n",
       "2      bonk overly sexual questions longer allowed  ...            18   \n",
       "3      bonk overly sexual questions longer allowed  ...            19   \n",
       "4      bonk overly sexual questions longer allowed  ...             6   \n",
       "...                                            ...  ...           ...   \n",
       "14633                           age consider prime  ...             1   \n",
       "14634                           age consider prime  ...             1   \n",
       "14635                           age consider prime  ...             1   \n",
       "14636                           age consider prime  ...             1   \n",
       "14637                           age consider prime  ...             1   \n",
       "\n",
       "      submission_ups    minmax  minmax_grouped  sentiment  comments_polarity  \\\n",
       "0              13949  0.535714        0.235294   positive            -0.0571   \n",
       "1              13949  0.428571        0.058824   positive            -0.6486   \n",
       "2              13949  0.785714        0.647059   positive             0.9062   \n",
       "3              13949  0.821429        0.705882   positive            -0.8020   \n",
       "4              13949  0.357143       -0.058824   positive             0.0000   \n",
       "...              ...       ...             ...        ...                ...   \n",
       "14633            373 -0.076923       -0.785714   negative            -0.3940   \n",
       "14634            373 -0.076923       -0.785714   negative             0.4215   \n",
       "14635            373 -0.076923       -0.785714   negative             0.9136   \n",
       "14636            373 -0.076923       -0.785714   negative             0.8020   \n",
       "14637            373 -0.076923       -0.785714   negative             0.3826   \n",
       "\n",
       "       comments_predicted_sentiment overestimated  underestimated subreddit  \n",
       "0                          negative             0               1    askmen  \n",
       "1                          negative             0               1    askmen  \n",
       "2                          positive             0               0    askmen  \n",
       "3                          negative             0               1    askmen  \n",
       "4                          negative             0               1    askmen  \n",
       "...                             ...           ...             ...       ...  \n",
       "14633                      negative             0               0  askwomen  \n",
       "14634                      positive             1               0  askwomen  \n",
       "14635                      positive             1               0  askwomen  \n",
       "14636                      positive             1               0  askwomen  \n",
       "14637                      positive             1               0  askwomen  \n",
       "\n",
       "[30809 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d7f2d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      askmen       0.85      0.86      0.86     16171\n",
      "    askwomen       0.85      0.83      0.84     14638\n",
      "\n",
      "    accuracy                           0.85     30809\n",
      "   macro avg       0.85      0.85      0.85     30809\n",
      "weighted avg       0.85      0.85      0.85     30809\n",
      "\n",
      "[[13942  2229]\n",
      " [ 2448 12190]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df['subreddit'],all_predictions))\n",
    "print(confusion_matrix(df['subreddit'],all_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61351f69",
   "metadata": {},
   "source": [
    "# Predicting from which subreddit does a post come from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a02095e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['askmen'], dtype='<U8')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_verse2 = [\"Fear thou not; for I am with thee: be not dismayed; for I am thy God: I will strengthen thee; yea, I will help thee; yea, I will uphold thee with the right hand of my righteousness.\"]\n",
    "vect2 = cv.transform(sample_verse2).toarray()\n",
    "model.predict(vect2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f0ed7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.externals import joblib\n",
    "#biblepredictionNV_model = open(\"biblepredictionNV_model.pkl\",\"wb\")\n",
    "#joblib.dump(clf,biblepredictionNV_model)\n",
    "#biblepredictionNV_model.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec41e26e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1094d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a685f784",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20562a5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22d4012",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daff119a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6ebff6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
