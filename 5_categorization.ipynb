{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fa87233",
   "metadata": {},
   "source": [
    "# Krystian Gronek & Katarzyna Piotrowska\n",
    "# Text Mining and Social Media Mining, final project - Analyzing men and women comments using NLP methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88dc8faa",
   "metadata": {},
   "source": [
    "# Loading packages and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "329449ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix, accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Naive Bayes Classifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "men = pd.read_csv('data/final_askmen.csv', sep = ';')\n",
    "women = pd.read_csv('data/final_askwomen.csv', sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "904187a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 30364 entries, 0 to 14362\n",
      "Data columns (total 24 columns):\n",
      " #   Column                            Non-Null Count  Dtype  \n",
      "---  ------                            --------------  -----  \n",
      " 0   username                          30364 non-null  object \n",
      " 1   com_original                      30364 non-null  object \n",
      " 2   cleaned                           30364 non-null  object \n",
      " 3   cleaned_wo_sw                     30364 non-null  object \n",
      " 4   tokenized                         30364 non-null  object \n",
      " 5   stemmed                           30364 non-null  object \n",
      " 6   tokenized_wo_sw                   30364 non-null  object \n",
      " 7   submission_title                  30364 non-null  object \n",
      " 8   submission_title_cleaned          30364 non-null  object \n",
      " 9   submission_title_cleaned_wo_sw    30364 non-null  object \n",
      " 10  submission_title_tokenized        30364 non-null  object \n",
      " 11  submission_title_stemmed          30364 non-null  object \n",
      " 12  submission_title_tokenized_wo_sw  30364 non-null  object \n",
      " 13  comment_score                     30364 non-null  int64  \n",
      " 14  submission_ups                    30364 non-null  int64  \n",
      " 15  minmax                            30364 non-null  float64\n",
      " 16  minmax_grouped                    29476 non-null  float64\n",
      " 17  is_positive                       30364 non-null  int64  \n",
      " 18  sentiment                         30364 non-null  object \n",
      " 19  comments_polarity                 30364 non-null  float64\n",
      " 20  comments_predicted_sentiment      30364 non-null  object \n",
      " 21  posts_polarity                    30364 non-null  float64\n",
      " 22  posts_predicted_sentiment         30364 non-null  object \n",
      " 23  subreddit                         30364 non-null  object \n",
      "dtypes: float64(4), int64(3), object(17)\n",
      "memory usage: 5.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# add categorical variable that distincs weather a observation comes from /r/AskMen subreddit or /r/AskWomen subreddit \n",
    "men['subreddit'] = np.repeat(\"askmen\", len(men))\n",
    "women['subreddit'] = np.repeat(\"askwomen\", len(women))\n",
    "\n",
    "# merge two datasets into one\n",
    "df = pd.concat([men, women], axis = 0)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082812e3",
   "metadata": {},
   "source": [
    "# Z GITHUBA (usunac to jak juz wybiore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0ae7eb",
   "metadata": {},
   "source": [
    "# Categorization of comments according to subreddit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "254b8da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Sparse Matrix:  (30364, 29942)\n",
      "Amount of non-zero occurences: 767382\n",
      "Sparsity: 0 %\n",
      "TfidfTransformer()\n",
      "(30364, 29942)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.7711180635600198"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['askmen' 'askmen' 'askmen' ... 'askwomen' 'askwomen' 'askwomen']\n",
      "Accuracy of Model - train data 84.41809723766004 %\n",
      "Accuracy of Model - test data 77.11180635600198 %\n"
     ]
    }
   ],
   "source": [
    "comments_cleaned = df['cleaned']\n",
    "subreddits = df['subreddit']\n",
    "\n",
    "# Vectorization\n",
    "# count how many times does a word occur in each message, term frequency\n",
    "# weigh the counts, so that frequent tokens get lower weight, inverse document frequency\n",
    "# normalize the vectors to unit length, to abstract from the original text length, L2 norm \n",
    "cv = CountVectorizer().fit(comments_cleaned);\n",
    "X = cv.transform(comments_cleaned);\n",
    "\n",
    "# the bag-of-words counts for the entire SMS corpus\n",
    "print('Shape of Sparse Matrix: ',X.shape)\n",
    "print('Amount of non-zero occurences:',X.nnz)\n",
    "\n",
    "# Sparsity\n",
    "sparsity =(100.0 * X.nnz/(X.shape[0]*X.shape[1]))\n",
    "print('Sparsity: {}'.format(round(sparsity)),\"%\")\n",
    "# THE SPARSITY IS equal to 0 % which is good.\n",
    "\n",
    "# Term weighting and normalization with TF-IDF\n",
    "tfidf_transformer=TfidfTransformer().fit(X)\n",
    "X_tfidf = tfidf_transformer.transform(X)\n",
    "print(tfidf_transformer)\n",
    "print(X_tfidf.shape)\n",
    "\n",
    "# split the data into train and test parts\n",
    "comment_train, comment_test, subreddit_train, subreddit_test = train_test_split(X, subreddits, test_size=0.2, random_state = 9);\n",
    "\n",
    "# Naive Bayes Classifier\n",
    "model = MultinomialNB();\n",
    "model.fit(comment_train,subreddit_train);\n",
    "model.score(comment_test,subreddit_test);\n",
    "\n",
    "# what is the quality of our model?\n",
    "all_predictions = model.predict(X_tfidf)\n",
    "print(all_predictions)\n",
    "\n",
    "# Accuracy of our Model - train data\n",
    "print(\"Accuracy of Model - train data\", model.score(comment_train,subreddit_train)*100,\"%\")\n",
    "\n",
    "# Accuracy of our Model - test data\n",
    "print(\"Accuracy of Model - test data\", model.score(comment_test,subreddit_test)*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0d7f2d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      askmen       0.83      0.87      0.85     16001\n",
      "    askwomen       0.85      0.81      0.83     14363\n",
      "\n",
      "    accuracy                           0.84     30364\n",
      "   macro avg       0.84      0.84      0.84     30364\n",
      "weighted avg       0.84      0.84      0.84     30364\n",
      "\n",
      "[[13997  2004]\n",
      " [ 2782 11581]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df['subreddit'],all_predictions))\n",
    "print(confusion_matrix(df['subreddit'],all_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61351f69",
   "metadata": {},
   "source": [
    "# Predicting from which subreddit does a comment come from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a02095e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['askmen'], dtype='<U8')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_verse2 = [\"Fear thou not; for I am with thee: be not dismayed; for I am thy God: I will strengthen thee; yea, I will help thee; yea, I will uphold thee with the right hand of my righteousness.\"]\n",
    "vect2 = cv.transform(sample_verse2).toarray()\n",
    "clf.predict(vect2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad35a09c",
   "metadata": {},
   "source": [
    "# Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f0ed7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.externals import joblib\n",
    "#biblepredictionNV_model = open(\"biblepredictionNV_model.pkl\",\"wb\")\n",
    "#joblib.dump(clf,biblepredictionNV_model)\n",
    "#biblepredictionNV_model.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db304c0b",
   "metadata": {},
   "source": [
    "# Z TWD (usunac to jak juz wybiore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec41e26e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1094d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a685f784",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20562a5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22d4012",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daff119a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6ebff6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
